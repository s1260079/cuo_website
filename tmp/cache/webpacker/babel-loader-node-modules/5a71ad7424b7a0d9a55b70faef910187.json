{"ast":null,"code":"\"use strict\";\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\n\nfunction _wrapNativeSuper(Class) { var _cache = typeof Map === \"function\" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== \"function\") { throw new TypeError(\"Super expression must either be null or a function\"); } if (typeof _cache !== \"undefined\") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }\n\nfunction _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }\n\nfunction _isNativeFunction(fn) { return Function.toString.call(fn).indexOf(\"[native code]\") !== -1; }\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Date.prototype.toString.call(Reflect.construct(Date, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar assert = require(\"assert\");\n\nvar backoff_1 = require(\"./backoff\");\n\nvar rate_limiter_1 = require(\"./rate-limiter\");\n\nvar timestamp_1 = require(\"./timestamp\");\n\nvar util_1 = require(\"./util\");\n\nvar write_batch_1 = require(\"./write-batch\");\n\nvar validate_1 = require(\"./validate\");\n\nvar logger_1 = require(\"./logger\");\n\nvar google_gax_1 = require(\"google-gax\");\n/*!\n * The maximum number of writes that can be in a single batch.\n */\n\n\nvar MAX_BATCH_SIZE = 20;\n/*!\n * The starting maximum number of operations per second as allowed by the\n * 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\n\nexports.DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND = 500;\n/*!\n * The rate by which to increase the capacity as specified by the 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\n\nvar RATE_LIMITER_MULTIPLIER = 1.5;\n/*!\n * How often the operations per second capacity should increase in milliseconds\n * as specified by the 500/50/5 rule.\n *\n * https://cloud.google.com/datastore/docs/best-practices#ramping_up_traffic.\n */\n\nvar RATE_LIMITER_MULTIPLIER_MILLIS = 5 * 60 * 1000;\n/**\n * Represents a single write for BulkWriter, encapsulating operation dispatch\n * and error handling.\n * @private\n */\n\nvar BulkWriterOperation = /*#__PURE__*/function () {\n  /**\n   * @param ref The document reference being written to.\n   * @param type The type of operation that created this write.\n   * @param sendFn A callback to invoke when the operation should be sent.\n   * @param errorFn The user provided global error callback.\n   * @param successFn The user provided global success callback.\n   */\n  function BulkWriterOperation(ref, type, sendFn, errorFn, successFn) {\n    _classCallCheck(this, BulkWriterOperation);\n\n    this.ref = ref;\n    this.type = type;\n    this.sendFn = sendFn;\n    this.errorFn = errorFn;\n    this.successFn = successFn;\n    this.deferred = new util_1.Deferred();\n    this.failedAttempts = 0;\n  }\n\n  _createClass(BulkWriterOperation, [{\n    key: \"promise\",\n    get: function get() {\n      return this.deferred.promise;\n    }\n  }, {\n    key: \"onError\",\n    value: function onError(error) {\n      ++this.failedAttempts;\n\n      try {\n        var bulkWriterError = new BulkWriterError(error.code, error.message, this.ref, this.type, this.failedAttempts);\n        var shouldRetry = this.errorFn(bulkWriterError);\n        logger_1.logger('BulkWriter.errorFn', null, 'Ran error callback on error code:', error.code, ', shouldRetry:', shouldRetry, ' for document:', this.ref.path);\n\n        if (shouldRetry) {\n          this.sendFn(this);\n        } else {\n          this.deferred.reject(bulkWriterError);\n        }\n      } catch (userCallbackError) {\n        this.deferred.reject(userCallbackError);\n      }\n    }\n  }, {\n    key: \"onSuccess\",\n    value: function onSuccess(result) {\n      try {\n        this.successFn(this.ref, result);\n        this.deferred.resolve(result);\n      } catch (userCallbackError) {\n        this.deferred.reject(userCallbackError);\n      }\n    }\n  }]);\n\n  return BulkWriterOperation;\n}();\n/**\n * Used to represent a batch on the BatchQueue.\n *\n * @private\n */\n\n\nvar BulkCommitBatch = /*#__PURE__*/function (_write_batch_1$WriteB) {\n  _inherits(BulkCommitBatch, _write_batch_1$WriteB);\n\n  var _super = _createSuper(BulkCommitBatch);\n\n  function BulkCommitBatch() {\n    var _this;\n\n    _classCallCheck(this, BulkCommitBatch);\n\n    _this = _super.apply(this, arguments); // The set of document reference paths present in the WriteBatch.\n\n    _this.docPaths = new Set(); // An array of pending write operations. Only contains writes that have not\n    // been resolved.\n\n    _this.pendingOps = [];\n    return _this;\n  }\n\n  _createClass(BulkCommitBatch, [{\n    key: \"has\",\n    value: function has(documentRef) {\n      return this.docPaths.has(documentRef.path);\n    }\n  }, {\n    key: \"bulkCommit\",\n    value: function () {\n      var _bulkCommit = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var options,\n            _a,\n            tag,\n            stack,\n            response,\n            retryCodes,\n            ops,\n            i,\n            DELETE_TIMESTAMP_SENTINEL,\n            status,\n            updateTime,\n            error,\n            _args = arguments;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                options = _args.length > 0 && _args[0] !== undefined ? _args[0] : {};\n                tag = (_a = options === null || options === void 0 ? void 0 : options.requestTag) !== null && _a !== void 0 ? _a : util_1.requestTag(); // Capture the error stack to preserve stack tracing across async calls.\n\n                stack = Error().stack;\n                _context.prev = 3;\n                logger_1.logger('BulkCommitBatch.bulkCommit', tag, \"Sending next batch with \".concat(this._opCount, \" writes\"));\n                retryCodes = util_1.getRetryCodes('batchWrite');\n                _context.next = 8;\n                return this._commit({\n                  retryCodes: retryCodes,\n                  methodName: 'batchWrite',\n                  requestTag: tag\n                });\n\n              case 8:\n                response = _context.sent;\n                _context.next = 15;\n                break;\n\n              case 11:\n                _context.prev = 11;\n                _context.t0 = _context[\"catch\"](3);\n                // Map the failure to each individual write's result.\n                ops = Array.from({\n                  length: this.pendingOps.length\n                });\n                response = {\n                  writeResults: ops.map(function () {\n                    return {};\n                  }),\n                  status: ops.map(function () {\n                    return _context.t0;\n                  })\n                };\n\n              case 15:\n                for (i = 0; i < (response.writeResults || []).length; ++i) {\n                  // Since delete operations currently do not have write times, use a\n                  // sentinel Timestamp value.\n                  // TODO(b/158502664): Use actual delete timestamp.\n                  DELETE_TIMESTAMP_SENTINEL = timestamp_1.Timestamp.fromMillis(0);\n                  status = (response.status || [])[i];\n\n                  if (status.code === google_gax_1.Status.OK) {\n                    updateTime = timestamp_1.Timestamp.fromProto(response.writeResults[i].updateTime || DELETE_TIMESTAMP_SENTINEL);\n                    this.pendingOps[i].onSuccess(new write_batch_1.WriteResult(updateTime));\n                  } else {\n                    error = new google_gax_1.GoogleError(status.message || undefined);\n                    error.code = status.code;\n                    this.pendingOps[i].onError(util_1.wrapError(error, stack));\n                  }\n                }\n\n              case 16:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[3, 11]]);\n      }));\n\n      function bulkCommit() {\n        return _bulkCommit.apply(this, arguments);\n      }\n\n      return bulkCommit;\n    }()\n    /**\n     * Helper to update data structures associated with the operation and returns\n     * the result.\n     */\n\n  }, {\n    key: \"processLastOperation\",\n    value: function processLastOperation(op) {\n      assert(!this.docPaths.has(op.ref.path), 'Batch should not contain writes to the same document');\n      this.docPaths.add(op.ref.path);\n      this.pendingOps.push(op);\n    }\n  }]);\n\n  return BulkCommitBatch;\n}(write_batch_1.WriteBatch);\n/**\n * The error thrown when a BulkWriter operation fails.\n *\n * @class BulkWriterError\n */\n\n\nvar BulkWriterError = /*#__PURE__*/function (_Error) {\n  _inherits(BulkWriterError, _Error);\n\n  var _super2 = _createSuper(BulkWriterError);\n\n  /** @hideconstructor */\n  function BulkWriterError(\n  /** The status code of the error. */\n  code,\n  /** The error message of the error. */\n  message,\n  /** The document reference the operation was performed on. */\n  documentRef,\n  /** The type of operation performed. */\n  operationType,\n  /** How many times this operation has been attempted unsuccessfully. */\n  failedAttempts) {\n    var _this2;\n\n    _classCallCheck(this, BulkWriterError);\n\n    _this2 = _super2.call(this, message);\n    _this2.code = code;\n    _this2.message = message;\n    _this2.documentRef = documentRef;\n    _this2.operationType = operationType;\n    _this2.failedAttempts = failedAttempts;\n    return _this2;\n  }\n\n  return BulkWriterError;\n}( /*#__PURE__*/_wrapNativeSuper(Error));\n\nexports.BulkWriterError = BulkWriterError;\n/**\n * A Firestore BulkWriter that can be used to perform a large number of writes\n * in parallel.\n *\n * @class BulkWriter\n */\n\nvar BulkWriter = /*#__PURE__*/function () {\n  /** @hideconstructor */\n  function BulkWriter(firestore, options) {\n    _classCallCheck(this, BulkWriter);\n\n    var _a, _b;\n\n    this.firestore = firestore;\n    /**\n     * The maximum number of writes that can be in a single batch.\n     * Visible for testing.\n     * @private\n     */\n\n    this._maxBatchSize = MAX_BATCH_SIZE;\n    /**\n     * The batch that is currently used to schedule operations. Once this batch\n     * reaches maximum capacity, a new batch is created.\n     * @private\n     */\n\n    this._bulkCommitBatch = new BulkCommitBatch(this.firestore);\n    /**\n     * A pointer to the tail of all active BulkWriter applications. This pointer\n     * is advanced every time a new write is enqueued.\n     * @private\n     */\n\n    this._lastOp = Promise.resolve();\n    /**\n     * Whether this BulkWriter instance has started to close. Afterwards, no\n     * new operations can be enqueued, except for retry operations scheduled by\n     * the error handler.\n     * @private\n     */\n\n    this._closing = false;\n    /**\n     * The user-provided callback to be run every time a BulkWriter operation\n     * successfully completes.\n     * @private\n     */\n\n    this._successFn = function () {};\n    /**\n     * The user-provided callback to be run every time a BulkWriter operation\n     * fails.\n     * @private\n     */\n\n\n    this._errorFn = function (error) {\n      var retryCodes = util_1.getRetryCodes('batchWrite');\n      return error.code !== undefined && retryCodes.includes(error.code) && error.failedAttempts < backoff_1.MAX_RETRY_ATTEMPTS;\n    };\n\n    this.firestore._incrementBulkWritersCount();\n\n    validateBulkWriterOptions(options);\n\n    if ((options === null || options === void 0 ? void 0 : options.throttling) === false) {\n      this._rateLimiter = new rate_limiter_1.RateLimiter(Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY);\n    } else {\n      var startingRate = exports.DEFAULT_STARTING_MAXIMUM_OPS_PER_SECOND;\n      var maxRate = Number.POSITIVE_INFINITY;\n\n      if (typeof (options === null || options === void 0 ? void 0 : options.throttling) !== 'boolean') {\n        if (((_a = options === null || options === void 0 ? void 0 : options.throttling) === null || _a === void 0 ? void 0 : _a.maxOpsPerSecond) !== undefined) {\n          maxRate = options.throttling.maxOpsPerSecond;\n        }\n\n        if (((_b = options === null || options === void 0 ? void 0 : options.throttling) === null || _b === void 0 ? void 0 : _b.initialOpsPerSecond) !== undefined) {\n          startingRate = options.throttling.initialOpsPerSecond;\n        } // The initial validation step ensures that the maxOpsPerSecond is\n        // greater than initialOpsPerSecond. If this inequality is true, that\n        // means initialOpsPerSecond was not set and maxOpsPerSecond is less\n        // than the default starting rate.\n\n\n        if (maxRate < startingRate) {\n          startingRate = maxRate;\n        } // Ensure that the batch size is not larger than the number of allowed\n        // operations per second.\n\n\n        if (startingRate < this._maxBatchSize) {\n          this._maxBatchSize = startingRate;\n        }\n      }\n\n      this._rateLimiter = new rate_limiter_1.RateLimiter(startingRate, RATE_LIMITER_MULTIPLIER, RATE_LIMITER_MULTIPLIER_MILLIS, maxRate);\n    }\n  }\n  /**\n   * Create a document with the provided data. This single operation will fail\n   * if a document exists at its location.\n   *\n   * @param {DocumentReference} documentRef A reference to the document to be\n   * created.\n   * @param {T} data The object to serialize as the document.\n   * @returns {Promise<WriteResult>} A promise that resolves with the result of\n   * the write. If the write fails, the promise is rejected with a\n   * [BulkWriterError]{@link BulkWriterError}.\n   *\n   * @example\n   * let bulkWriter = firestore.bulkWriter();\n   * let documentRef = firestore.collection('col').doc();\n   *\n   * bulkWriter\n   *  .create(documentRef, {foo: 'bar'})\n   *  .then(result => {\n   *    console.log('Successfully executed write at: ', result);\n   *  })\n   *  .catch(err => {\n   *    console.log('Write failed with: ', err);\n   *  });\n   * });\n   */\n\n\n  _createClass(BulkWriter, [{\n    key: \"create\",\n    value: function create(documentRef, data) {\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'create', function (bulkCommitBatch) {\n        return bulkCommitBatch.create(documentRef, data);\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Delete a document from the database.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * deleted.\n     * @param {Precondition=} precondition A precondition to enforce for this\n     * delete.\n     * @param {Timestamp=} precondition.lastUpdateTime If set, enforces that the\n     * document was last updated at lastUpdateTime. Fails the batch if the\n     * document doesn't exist or was last updated at a different time.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the delete. If the delete fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .delete(documentRef)\n     *  .then(result => {\n     *    console.log('Successfully deleted document');\n     *  })\n     *  .catch(err => {\n     *    console.log('Delete failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"delete\",\n    value: function _delete(documentRef, precondition) {\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'delete', function (bulkCommitBatch) {\n        return bulkCommitBatch[\"delete\"](documentRef, precondition);\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Write to the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document does not\n     * exist yet, it will be created. If you pass [SetOptions]{@link SetOptions}.,\n     * the provided data can be merged into the existing document.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * set.\n     * @param {T} data The object to serialize as the document.\n     * @param {SetOptions=} options An object to configure the set behavior.\n     * @param {boolean=} options.merge - If true, set() merges the values\n     * specified in its data argument. Fields omitted from this set() call remain\n     * untouched.\n     * @param {Array.<string|FieldPath>=} options.mergeFields - If provided, set()\n     * only replaces the specified field paths. Any field path that is not\n     * specified is ignored and remains untouched.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.collection('col').doc();\n     *\n     * bulkWriter\n     *  .set(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(documentRef, data, options) {\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'set', function (bulkCommitBatch) {\n        return bulkCommitBatch.set(documentRef, data, options);\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Update fields of the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document doesn't yet\n     * exist, the update fails and the entire batch will be rejected.\n     *\n     * The update() method accepts either an object with field paths encoded as\n     * keys and field values encoded as values, or a variable number of arguments\n     * that alternate between field paths and field values. Nested fields can be\n     * updated by providing dot-separated field path strings or by providing\n     * FieldPath objects.\n     *\n     *\n     * A Precondition restricting this update can be specified as the last\n     * argument.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * updated.\n     * @param {UpdateData|string|FieldPath} dataOrField An object containing the\n     * fields and values with which to update the document or the path of the\n     * first field to update.\n     * @param {...(Precondition|*|string|FieldPath)} preconditionOrValues - An\n     * alternating list of field paths and values to update or a Precondition to\n     * restrict this update\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .update(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"update\",\n    value: function update(documentRef, dataOrField) {\n      for (var _len = arguments.length, preconditionOrValues = new Array(_len > 2 ? _len - 2 : 0), _key = 2; _key < _len; _key++) {\n        preconditionOrValues[_key - 2] = arguments[_key];\n      }\n\n      this._verifyNotClosed();\n\n      var op = this._enqueue(documentRef, 'update', function (bulkCommitBatch) {\n        return bulkCommitBatch.update.apply(bulkCommitBatch, [documentRef, dataOrField].concat(preconditionOrValues));\n      });\n\n      util_1.silencePromise(op);\n      return op;\n    }\n    /**\n     * Attaches a listener that is run every time a BulkWriter operation\n     * successfully completes.\n     *\n     * @param callback A callback to be called every time a BulkWriter operation\n     * successfully completes.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteResult((documentRef, result) => {\n     *     console.log(\n     *       'Successfully executed write on document: ',\n     *       documentRef,\n     *       ' at: ',\n     *       result\n     *     );\n     *   });\n     */\n\n  }, {\n    key: \"onWriteResult\",\n    value: function onWriteResult(callback) {\n      this._successFn = callback;\n    }\n    /**\n     * Attaches an error handler listener that is run every time a BulkWriter\n     * operation fails.\n     *\n     * BulkWriter has a default error handler that retries UNAVAILABLE and\n     * ABORTED errors up to a maximum of 10 failed attempts. When an error\n     * handler is specified, the default error handler will be overwritten.\n     *\n     * @param shouldRetryCallback A callback to be called every time a BulkWriter\n     * operation fails. Returning `true` will retry the operation. Returning\n     * `false` will stop the retry loop.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteError((error) => {\n     *     if (\n     *       error.code === GrpcStatus.UNAVAILABLE &&\n     *       error.failedAttempts < MAX_RETRY_ATTEMPTS\n     *     ) {\n     *       return true;\n     *     } else {\n     *       console.log('Failed write at document: ', error.documentRef);\n     *       return false;\n     *     }\n     *   });\n     */\n\n  }, {\n    key: \"onWriteError\",\n    value: function onWriteError(shouldRetryCallback) {\n      this._errorFn = shouldRetryCallback;\n    }\n    /**\n     * Commits all writes that have been enqueued up to this point in parallel.\n     *\n     * Returns a Promise that resolves when all currently queued operations have\n     * been committed. The Promise will never be rejected since the results for\n     * each individual operation are conveyed via their individual Promises.\n     *\n     * The Promise resolves immediately if there are no pending writes. Otherwise,\n     * the Promise waits for all previously issued writes, but it does not wait\n     * for writes that were added after the method is called. If you want to wait\n     * for additional writes, call `flush()` again.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await flush().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n\n  }, {\n    key: \"flush\",\n    value: function flush() {\n      this._verifyNotClosed();\n\n      this._sendCurrentBatch(\n      /* flush= */\n      true);\n\n      return this._lastOp;\n    }\n    /**\n     * Commits all enqueued writes and marks the BulkWriter instance as closed.\n     *\n     * After calling `close()`, calling any method wil throw an error. Any\n     * retries scheduled as part of an `onWriteError()` handler will be run\n     * before the `close()` promise resolves.\n     *\n     * Returns a Promise that resolves when there are no more pending writes. The\n     * Promise will never be rejected. Calling this method will send all requests.\n     * The promise resolves immediately if there are no pending writes.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await close().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n\n  }, {\n    key: \"close\",\n    value: function close() {\n      this._verifyNotClosed();\n\n      this.firestore._decrementBulkWritersCount();\n\n      var flushPromise = this.flush();\n      this._closing = true;\n      return flushPromise;\n    }\n    /**\n     * Throws an error if the BulkWriter instance has been closed.\n     * @private\n     */\n\n  }, {\n    key: \"_verifyNotClosed\",\n    value: function _verifyNotClosed() {\n      if (this._closing) {\n        throw new Error('BulkWriter has already been closed.');\n      }\n    }\n    /**\n     * Sends the current batch and resets `this._bulkCommitBatch`.\n     *\n     * @param flush If provided, keeps re-sending operations until no more\n     * operations are enqueued. This allows retries to resolve as part of a\n     * `flush()` or `close()` call.\n     * @private\n     */\n\n  }, {\n    key: \"_sendCurrentBatch\",\n    value: function _sendCurrentBatch() {\n      var _this3 = this;\n\n      var flush = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      if (this._bulkCommitBatch._opCount === 0) return;\n      var tag = util_1.requestTag();\n      var pendingBatch = this._bulkCommitBatch;\n      this._bulkCommitBatch = new BulkCommitBatch(this.firestore); // Send the batch if it is under the rate limit, or schedule another\n      // attempt after the appropriate timeout.\n\n      var underRateLimit = this._rateLimiter.tryMakeRequest(pendingBatch._opCount);\n\n      var delayedExecution = new util_1.Deferred();\n\n      if (underRateLimit) {\n        delayedExecution.resolve();\n      } else {\n        var delayMs = this._rateLimiter.getNextRequestDelayMs(pendingBatch._opCount);\n\n        logger_1.logger('BulkWriter._sendCurrentBatch', tag, \"Backing off for \".concat(delayMs, \" seconds\"));\n        backoff_1.delayExecution(function () {\n          return delayedExecution.resolve();\n        }, delayMs);\n      }\n\n      delayedExecution.promise.then( /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return pendingBatch.bulkCommit({\n                  requestTag: tag\n                });\n\n              case 2:\n                if (flush) _this3._sendCurrentBatch(flush);\n\n              case 3:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2);\n      })));\n    }\n    /**\n     * Schedules and runs the provided operation on the next available batch.\n     * @private\n     */\n\n  }, {\n    key: \"_enqueue\",\n    value: function _enqueue(ref, type, enqueueOnBatchCallback) {\n      var bulkWriterOp = new BulkWriterOperation(ref, type, this._sendFn.bind(this, enqueueOnBatchCallback), this._errorFn.bind(this), this._successFn.bind(this));\n\n      this._sendFn(enqueueOnBatchCallback, bulkWriterOp);\n\n      return bulkWriterOp.promise;\n    }\n    /**\n     * Schedules the provided operations on current BulkCommitBatch.\n     * Sends the BulkCommitBatch if it reaches maximum capacity.\n     *\n     * @private\n     */\n\n  }, {\n    key: \"_sendFn\",\n    value: function _sendFn(enqueueOnBatchCallback, op) {\n      if (this._bulkCommitBatch.has(op.ref)) {\n        // Create a new batch since the backend doesn't support batches with two\n        // writes to the same document.\n        this._sendCurrentBatch();\n      } // Run the operation on the current batch and advance the `_lastOp` pointer.\n      // This ensures that `_lastOp` only resolves when both the previous and the\n      // current write resolves.\n\n\n      enqueueOnBatchCallback(this._bulkCommitBatch);\n\n      this._bulkCommitBatch.processLastOperation(op);\n\n      this._lastOp = this._lastOp.then(function () {\n        return util_1.silencePromise(op.promise);\n      });\n\n      if (this._bulkCommitBatch._opCount === this._maxBatchSize) {\n        this._sendCurrentBatch();\n      }\n    }\n  }]);\n\n  return BulkWriter;\n}();\n\nexports.BulkWriter = BulkWriter;\n/**\n * Validates the use of 'value' as BulkWriterOptions.\n *\n * @private\n * @param value The BulkWriterOptions object to validate.\n * @throws if the input is not a valid BulkWriterOptions object.\n */\n\nfunction validateBulkWriterOptions(value) {\n  if (validate_1.validateOptional(value, {\n    optional: true\n  })) {\n    return;\n  }\n\n  var argName = 'options';\n\n  if (!util_1.isObject(value)) {\n    throw new Error(\"\".concat(validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument'), \" Input is not an object.\"));\n  }\n\n  var options = value;\n\n  if (options.throttling === undefined || typeof options.throttling === 'boolean') {\n    return;\n  }\n\n  if (options.throttling.initialOpsPerSecond !== undefined) {\n    validate_1.validateInteger('initialOpsPerSecond', options.throttling.initialOpsPerSecond, {\n      minValue: 1\n    });\n  }\n\n  if (options.throttling.maxOpsPerSecond !== undefined) {\n    validate_1.validateInteger('maxOpsPerSecond', options.throttling.maxOpsPerSecond, {\n      minValue: 1\n    });\n\n    if (options.throttling.initialOpsPerSecond !== undefined && options.throttling.initialOpsPerSecond > options.throttling.maxOpsPerSecond) {\n      throw new Error(\"\".concat(validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument'), \" \\\"maxOpsPerSecond\\\" cannot be less than \\\"initialOpsPerSecond\\\".\"));\n    }\n  }\n}","map":null,"metadata":{},"sourceType":"module"}